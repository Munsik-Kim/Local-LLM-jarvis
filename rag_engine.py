# rag_engine.py - ìµœì‹  LangChain ë²„ì „ ëŒ€ì‘ ì™„ë£Œ
import os
import pdfplumber

# [ìˆ˜ì •ë¨ 1] í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° ê²½ë¡œ ë³€ê²½
# ê¸°ì¡´: from langchain.text_splitter import RecursiveCharacterTextSplitter (ì‚­ì œ)
# ìµœì‹ : langchain_text_splitters íŒ¨í‚¤ì§€ ì‚¬ìš©
from langchain_text_splitters import RecursiveCharacterTextSplitter

# [ìˆ˜ì •ë¨ 2] ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ (ê·¸ëŒ€ë¡œ ìœ ì§€)
from langchain_huggingface import HuggingFaceEmbeddings

# [ìˆ˜ì •ë¨ 3] ë²¡í„° DB ê²½ë¡œ (ê·¸ëŒ€ë¡œ ìœ ì§€)
from langchain_community.vectorstores import Chroma

# [ìˆ˜ì •ë¨ 4] Document ê°ì²´ ê²½ë¡œ ë³€ê²½
from langchain_core.documents import Document 

# 1. ë²¡í„° DB ì €ì¥ ê²½ë¡œ
PERSIST_DIRECTORY = os.path.join(os.getcwd(), "db_storage")

# 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_model = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask"
)

def process_document(file_path):
    """
    ë¬¸ì„œë¥¼ ì½ì–´ì„œ -> ìª¼ê°œê³  -> ë²¡í„° DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    print(f"ğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path}")
    
    # (1) PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    text = ""
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            extracted = page.extract_text()
            if extracted:
                text += extracted + "\n"
    
    if not text:
        return "ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # (2) í…ìŠ¤íŠ¸ ìª¼ê°œê¸° (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    
    # LangChainìš© ë¬¸ì„œ ê°ì²´ë¡œ ë³€í™˜
    docs = [Document(page_content=x) for x in text_splitter.split_text(text)]
    
    # (3) ë²¡í„° DB ìƒì„± ë° ì €ì¥
    vector_db = Chroma.from_documents(
        documents=docs,
        embedding=embedding_model,
        persist_directory=PERSIST_DIRECTORY,
        collection_name="jarvis_docs"
    )
    
    print(f"âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ! ì´ {len(docs)}ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ì €ì¥ë¨.")
    return f"ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ! ì´ {len(docs)}ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."

def query_rag(question):
    """
    ì§ˆë¬¸ì„ ë°›ì•„ì„œ -> ê´€ë ¨ëœ ë¬¸ì„œ ì¡°ê°ì„ ì°¾ì•„ì„œ -> ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜
    """
    # ì €ì¥ëœ DB ë¶ˆëŸ¬ì˜¤ê¸°
    vector_db = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embedding_model,
        collection_name="jarvis_docs"
    )
    
    # (1) ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì¡°ê° 3ê°œ ê²€ìƒ‰ (k=3)
    docs = vector_db.similarity_search(question, k=3)
    
    # (2) ì°¾ì€ ì¡°ê°ë“¤ì˜ ë‚´ìš©ì„ í•©ì¹¨
    context = "\n\n".join([doc.page_content for doc in docs])
    
    return context