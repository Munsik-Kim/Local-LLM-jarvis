# app.py - ìµœì¢… ì™„ì„±í˜• (RAG + Vision + Tools + Memory + GUI)
import streamlit as st
import ollama
import os
import shutil
from tts_engine import speak
from vision_engine import analyze_image
from function_engine import execute_command, save_to_file
from rag_engine import process_document, query_rag
# [ì‹ ê·œ] ê¸°ì–µ ê´€ë¦¬ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from db_handler import init_db, save_message, load_messages, clear_db

# 0. DB ì´ˆê¸°í™” (ì•± ì¼¤ ë•Œ í•œ ë²ˆ ì‹¤í–‰)
init_db()

st.set_page_config(page_title="Jarvis Pro", page_icon="ğŸ§ ", layout="wide")
st.title("ğŸ§  JARVIS Pro (Memory Edition)")
st.caption("ê¸°ì–µë ¥(DB)ê¹Œì§€ ê°–ì¶˜ ì™„ë²½í•œ ë¡œì»¬ AI ì—ì´ì „íŠ¸")

# 2. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì œì–´ íŒ¨ë„")
    voice_on = st.toggle("ìŒì„± ë‹µë³€ (TTS)", value=True)
    st.divider()
    
    st.header("ğŸ“š ì§€ì‹ ì£¼ì… (RAG)")
    uploaded_file = st.file_uploader("í•™ìŠµìš© ë¬¸ì„œ(PDF)", type=['pdf'])
    
    if uploaded_file is not None:
        save_path = os.path.join(os.getcwd(), uploaded_file.name)
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        if "last_uploaded" not in st.session_state or st.session_state.last_uploaded != uploaded_file.name:
            with st.spinner("ë¬¸ì„œ í•™ìŠµ ì¤‘..."):
                result_msg = process_document(save_path)
                st.success(result_msg)
                st.session_state.last_uploaded = uploaded_file.name
                
        if os.path.exists(save_path):
            os.remove(save_path)

    st.divider()
    
    # [ìˆ˜ì •ë¨] ê¸°ì–µ ì‚­ì œ ë²„íŠ¼ì´ DBê¹Œì§€ ë‚ ë¦¬ë„ë¡ ë³€ê²½
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ì–µ ì‚­ì œ"):
        clear_db() # DB ì‚­ì œ
        st.session_state.messages = [] # í™”ë©´ ì‚­ì œ
        st.rerun()

    st.header("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„")
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼", type=['png', 'jpg', 'jpeg'])

# 3. [ì¤‘ìš”] ì„¸ì…˜ ê¸°ë¡ ì´ˆê¸°í™” (DB ì—°ë™) â­
if "messages" not in st.session_state:
    # DBì—ì„œ ê³¼ê±° ê¸°ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    db_history = load_messages()
    
    if db_history:
        st.session_state.messages = db_history
        st.info(f"ğŸ“ ê³¼ê±° ëŒ€í™” ê¸°ë¡ {len(db_history)}ê±´ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    else:
        # ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒˆë¡œ ì‹œì‘
        # (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í™”ë©´ì— ì•ˆ ë³´ì´ë¯€ë¡œ DB ì €ì¥ ì•ˆ í•´ë„ ë¨, í•˜ì§€ë§Œ ì—¬ê¸°ì„  íë¦„ìƒ ë¦¬ìŠ¤íŠ¸ì—ë§Œ ë„£ìŒ)
        st.session_state.messages = [
            {"role": "system", "content": "ë„ˆëŠ” ìœ ëŠ¥í•œ ë¹„ì„œ ìë¹„ìŠ¤ë‹¤. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•´ë¼."}
        ]

# 4. ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# 5. ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ì…ë ¥ í™”ë©´ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # (2) ì‚¬ìš©ì ì…ë ¥ ì €ì¥ (Session + DB) â­
    st.session_state.messages.append({"role": "user", "content": prompt})
    save_message("user", prompt) # DB ì €ì¥

    # (3) ë‹µë³€ ì²˜ë¦¬
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # A. ëª…ë ¹ì–´ ì²˜ë¦¬
        is_command, result_msg = execute_command(prompt)
        if is_command:
            if result_msg.startswith("REPORT:"):
                # (ë³´ê³ ì„œ ë¡œì§ ìƒëµ - í•„ìš”ì‹œ ì´ì „ ì½”ë“œ ì°¸ì¡°)
                full_response = result_msg 
            else:
                full_response = result_msg

        # B. ì´ë¯¸ì§€ ë¶„ì„
        elif uploaded_image is not None:
            temp_path = "temp_image.jpg"
            with open(temp_path, "wb") as f:
                f.write(uploaded_image.getbuffer())
            message_placeholder.markdown("ğŸ‘€ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
            analysis_result = analyze_image(temp_path)
            full_response = f"**[ì´ë¯¸ì§€ ë¶„ì„]**\n{analysis_result}"

        # C. RAG + ëŒ€í™”
        else:
            try:
                retrieved_context = query_rag(prompt)
            except:
                retrieved_context = ""

            if retrieved_context:
                final_prompt = f"""
                [ì°¸ê³  ë¬¸ì„œ] {retrieved_context}
                [ì§ˆë¬¸] {prompt}
                ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´.
                """
            else:
                final_prompt = prompt

            stream = ollama.chat(model='llama3.1', messages=st.session_state.messages, stream=True)
            for chunk in stream:
                full_response += chunk['message']['content']
                message_placeholder.markdown(full_response + "â–Œ")

        # (4) ìµœì¢… ì¶œë ¥ ë° ì €ì¥ (Session + DB) â­
        message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})
        save_message("assistant", full_response) # DB ì €ì¥
        
        if voice_on and len(full_response) < 200:
            speak(full_response)